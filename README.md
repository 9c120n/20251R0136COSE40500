# 2025-1R COSE405-00 Assignment 8

#### Research 1. Mixtral of Experts (2024, https://arxiv.org/abs/2401.04088)
#### Research 2. DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning (2025, https://arxiv.org/abs/2501.12948)
#### Research 3. The Llama 3 Herd of Models (2024, The https://arxiv.org/abs/2407.21783)
#### Research 4. Gemma: Open Models Based on Gemini Research and Technology (2024, https://arxiv.org/abs/2403.08295)
#### Research 5. Transformers Are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality (2024, https://arxiv.org/abs/2405.21060)
#### Research 6. RewardBench: Evaluating Reward Models for Language Modeling (2024, https://arxiv.org/abs/2403.13787)
